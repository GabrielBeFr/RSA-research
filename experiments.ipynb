{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = np.array([[1,0,0,0],[0,1,1,1],[0,0,0,1]])\n",
    "priors = np.array([0.25,0.25,0.25,0.25])\n",
    "costs = np.array([0,0,0])\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         0.33333333 0.33333333 0.33333333]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "listener_probabilities = np.copy(lexicon)\n",
    "listener_probabilities = listener_probabilities * priors\n",
    "listener_probabilities = preprocessing.normalize(listener_probabilities, norm='l1', axis=1)\n",
    "print(listener_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         1.         0.03571429]\n",
      " [0.         0.         0.         0.96428571]]\n"
     ]
    }
   ],
   "source": [
    "speaker_probabilities = np.copy(listener_probabilities)\n",
    "speaker_probabilities = np.power(speaker_probabilities, 3)\n",
    "speaker_probabilities = (speaker_probabilities.T * np.exp(-alpha * costs)).T\n",
    "speaker_probabilities = preprocessing.normalize(speaker_probabilities, norm='l1', axis=0)\n",
    "print(speaker_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 1], [0, 1], [1, 0]], [[1, 1], [0, 1], [1, 0]], [[1, 1], [0, 1], [1, 0]]]\n",
      "[[[1 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [0 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 0]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 0]\n",
      "  [1 0]]]\n"
     ]
    }
   ],
   "source": [
    "def generate_meanings(utterance, offset=0):\n",
    "    '''Infer the meanings from the world's lexicon.\n",
    "    input:\n",
    "    * utterance, an integer, the utterance to infer from\n",
    "\n",
    "    output: \n",
    "    * generated_meanings, a 2D array of boolean, the inferred meanings\n",
    "    '''\n",
    "    generated_meanings = []\n",
    "    if np.any(utterance):\n",
    "        generated_meanings.append(utterance)\n",
    "        for i in range(offset,len(utterance)):\n",
    "            meaning = utterance[i]\n",
    "            if meaning:\n",
    "                new_utterance = utterance.copy()\n",
    "                new_utterance[i] = 0\n",
    "                generated_meanings.extend(generate_meanings(new_utterance, offset+i))\n",
    "    return generated_meanings\n",
    "\n",
    "def generate_lexica(huge_lexicon, incomplete_lexicon=[], offset=0):\n",
    "    generated_lexica = []\n",
    "    current_utterance = huge_lexicon[offset]\n",
    "    current_lexicon = incomplete_lexicon.copy()\n",
    "    for j, meaning in enumerate(current_utterance):\n",
    "        if j == 0:\n",
    "            current_lexicon.append(meaning)\n",
    "        else:\n",
    "            current_lexicon[-1] = meaning\n",
    "\n",
    "        if offset < len(huge_lexicon)-1:\n",
    "            generated_lexica.extend(generate_lexica(huge_lexicon, current_lexicon, offset+1))\n",
    "        else:\n",
    "            generated_lexica.append(current_lexicon)\n",
    "\n",
    "    return generated_lexica\n",
    "\n",
    "lexicon = [[1,1],[1,1],[1,1]]\n",
    "huge_lexicon = []\n",
    "for i, utterance in enumerate(lexicon):\n",
    "    huge_lexicon.append(generate_meanings(utterance))\n",
    "print(huge_lexicon)\n",
    "lexica = generate_lexica(huge_lexicon)\n",
    "lexica = np.array(lexica)\n",
    "print(lexica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.         0.         0.         0.        ]\n",
      "  [0.         0.33333333 0.33333333 0.33333333]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.5        0.5       ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         0.5        0.         0.5       ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[1.         0.         0.         0.        ]\n",
      "  [0.         0.5        0.5        0.        ]\n",
      "  [0.         0.         0.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "listener_probabilities = np.copy(lexica)\n",
    "listener_probabilities = listener_probabilities * priors\n",
    "for i in range(len(listener_probabilities)):\n",
    "    listener_probabilities[i] = preprocessing.normalize(listener_probabilities[i], norm='l1', axis=1)\n",
    "print(listener_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
